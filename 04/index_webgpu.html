<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta http-equiv="encoding" content="utf-8" />
    <link rel="icon" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3E%3Crect width='16' height='16' fill='%23006'/%3E%3Ccircle cx='8' cy='8' r='5' fill='%23fff'/%3E%3C/svg%3E"/>
    <title>WebGPU Fish</title>
    <style>
      html, body {
        background-color: #000;
        margin: 0;
        padding: 0;
        height: 100%;
        overflow: hidden !important;
      }
      body {
        background: url('https://cs460.org/assignments/04/bg.jpg');
        background-size: cover;
      }
      #c {
        width: 100%;
        height: 100%;
        display: block;
      }
      #audioHint {
        position: absolute; left: 10px; top: 10px; color: #fff; font-family: system-ui, sans-serif; font-size: 13px;
        background: rgba(0,0,0,.4); padding: 6px 10px; border-radius: 6px;
      }
    </style>
  </head>
  <body>
    <!-- background song; place underwater-ambience-6201.mp3 in this folder; press B to play/pause -->
    <audio id="bgSong" src="underwater-ambience-6201.mp3" loop preload="auto" playsinline></audio>
    <div id="audioHint">
      Press B to enable/stop sound<br>
      Press W/S to move the big fish up/down
    </div>
    <canvas id="c"></canvas>

    <script type="module">
      // Minimal WebGPU port of the WebGL fish scene
      const canvas = document.getElementById('c');
      canvas.width = innerWidth; canvas.height = innerHeight;

      if (!('gpu' in navigator)) {
        const hint = document.getElementById('audioHint');
        if (hint) hint.textContent = 'WebGPU not available in this browser. Try Chrome/Edge 113+.';
        throw new Error('WebGPU not supported');
      }

      const adapter = await navigator.gpu.requestAdapter();
      const device = await adapter.requestDevice();
      const context = canvas.getContext('webgpu');
      const format = navigator.gpu.getPreferredCanvasFormat();
      context.configure({ device, format, alphaMode: 'premultiplied' });

      // Bubble sound (Web Audio) to match WebGL behavior on W/S
      let audioCtx = null;
      const keyDownOnce = { w: false, s: false };
      function initAudioCtx() {
        if (!audioCtx) {
          const AC = window.AudioContext || window.webkitAudioContext;
          if (AC) audioCtx = new AC();
        }
      }
      function playBubble(freq) {
        if (!audioCtx) return;
        const o = audioCtx.createOscillator();
        const g = audioCtx.createGain();
        o.type = 'sine';
        o.frequency.setValueAtTime(freq || 700, audioCtx.currentTime);
        o.connect(g); g.connect(audioCtx.destination);
        const now = audioCtx.currentTime;
        g.gain.setValueAtTime(0.0, now);
        g.gain.linearRampToValueAtTime(0.2, now + 0.02);
        g.gain.exponentialRampToValueAtTime(0.0001, now + 0.25);
        o.start(now);
        o.stop(now + 0.3);
      }

      // WGSL shaders
      const shaderModule = device.createShaderModule({
        code: /* wgsl */`
struct Uniforms {
  transform : mat4x4<f32>,
  color : vec4<f32>,
};
@group(0) @binding(0) var<uniform> uniforms : Uniforms;

struct VSOut {
  @builtin(position) Position : vec4<f32>,
};

@vertex
fn vs_main(@location(0) position : vec3<f32>) -> VSOut {
  var out : VSOut;
  out.Position = uniforms.transform * vec4<f32>(position, 1.0);
  return out;
}

@fragment
fn fs_main() -> @location(0) vec4<f32> {
  return uniforms.color;
}
        `,
      });

      // Pipeline
      const pipeline = device.createRenderPipeline({
        layout: 'auto',
        vertex: {
          module: shaderModule,
          entryPoint: 'vs_main',
          buffers: [
            {
              arrayStride: 12,
              attributes: [{ shaderLocation: 0, offset: 0, format: 'float32x3' }],
            },
          ],
        },
        fragment: {
          module: shaderModule,
          entryPoint: 'fs_main',
          targets: [{
            format,
            blend: {
              color: { srcFactor: 'src-alpha', dstFactor: 'one-minus-src-alpha', operation: 'add' },
              alpha: { srcFactor: 'one', dstFactor: 'one-minus-src-alpha', operation: 'add' },
            },
          }],
        },
        primitive: { topology: 'triangle-list' },
      });

      // Fish geometry (same as WebGL version) -------------------------
      const vertices = new Float32Array([
        0.5,  0.0, 0.0, // 0 nose
        0.2,  0.25,0.0, // 1 upper body
       -0.2,  0.15,0.0, // 2 upper tail base
       -0.4,  0.3, 0.0, // 3 upper tail tip
       -0.4, -0.3, 0.0, // 4 lower tail tip
       -0.2, -0.15,0.0, // 5 lower tail base
        0.2, -0.25,0.0  // 6 lower body
      ]);
      const indices = new Uint16Array([
        0,1,6,
        1,2,6,
        2,5,6,
        2,3,5,
        3,4,5,
      ]);
      // Pad indices to 4-byte multiple for writeBuffer (Uint16 count must be even)
      const indexCount = indices.length;
      const paddedIndexCount = (indexCount % 2 === 0) ? indexCount : indexCount + 1;
      const indicesPadded = new Uint16Array(paddedIndexCount);
      indicesPadded.set(indices);

      const vbuf = device.createBuffer({
        size: vertices.byteLength,
        usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
        mappedAtCreation: true,
      });
      new Float32Array(vbuf.getMappedRange()).set(vertices);
      vbuf.unmap();

      const ibuf = device.createBuffer({
        size: indicesPadded.byteLength,
        usage: GPUBufferUsage.INDEX | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(ibuf, 0, indicesPadded.buffer, indicesPadded.byteOffset, indicesPadded.byteLength);

      // Uniforms: 4x4 matrix (64 bytes) + color (16 bytes) = 80 bytes
      const uniformBufferSize = 80;
      // Eye vertex buffer (we'll rewrite it per-fish each frame)
      const eyeBuffer = device.createBuffer({
        size: 6 * 3 * 4, // 6 vertices * vec3<f32>
        usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
      });

      // Scene setup -----------------------------------------------------
      const all_fish = [];
      // helper constructors
      const f32 = (...v) => new Float32Array(v);

      function createFish(offset, color, scale = 1, direction = 1) {
        return { offset: f32(...offset), color: f32(...color), scale, direction };
      }

      // big fish (left-moving)
      all_fish.push(createFish([0, 0, 0], [1, 0, 0, 0.7], 1, -1));
      // small random fish
      for (let i = 0; i < 20; i++) {
        const rc = f32(Math.random(), Math.random(), Math.random(), 1);
        const ro = f32(Math.random() - Math.random(), Math.random() - Math.random(), 0);
        const rs = Math.random() * 0.3;
        all_fish.push(createFish(ro, rc, rs, 1));
      }

      // Create dedicated uniform buffers + bind groups per fish (separate for body and eye)
      for (const f of all_fish) {
        f.ubufBody = device.createBuffer({ size: uniformBufferSize, usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST });
        f.bindBody = device.createBindGroup({
          layout: pipeline.getBindGroupLayout(0),
          entries: [{ binding: 0, resource: { buffer: f.ubufBody } }],
        });
        f.ubufEye = device.createBuffer({ size: uniformBufferSize, usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST });
        f.bindEye = device.createBindGroup({
          layout: pipeline.getBindGroupLayout(0),
          entries: [{ binding: 0, resource: { buffer: f.ubufEye } }],
        });
      }

      // Keyboard control for the big fish (index 0) and B to toggle background song
      const keyState = { w: false, s: false };
      addEventListener('keydown', (e) => {
        if (e.key === 'w' || e.key === 'W') {
          keyState.w = true;
          initAudioCtx();
          if (!keyDownOnce.w) { playBubble(760); keyDownOnce.w = true; }
        }
        if (e.key === 's' || e.key === 'S') {
          keyState.s = true;
          initAudioCtx();
          if (!keyDownOnce.s) { playBubble(520); keyDownOnce.s = true; }
        }
        if (e.key === 'b' || e.key === 'B') {
          const el = document.getElementById('bgSong');
          const hint = document.getElementById('audioHint');
          if (el) {
            if (el.paused) {
              const p = el.play();
              if (p && p.then) {
                p.then(() => { if (hint) hint.style.display = 'none'; });
                if (p.catch) p.catch(() => { if (hint) hint.style.display = 'block'; });
              }
            } else {
              el.pause();
              if (hint) hint.style.display = 'block';
            }
          }
        }
      });
      addEventListener('keyup',   (e) => {
        if (e.key === 'w' || e.key === 'W') { keyState.w = false; keyDownOnce.w = false; }
        if (e.key === 's' || e.key === 'S') { keyState.s = false; keyDownOnce.s = false; }
      });

      // set default volume
      (function(){ const el = document.getElementById('bgSong'); if (el) el.volume = 0.2; })();

      const uni = new Float32Array(uniformBufferSize / 4);

      function draw() {
        // movement update
        // First pass: draw all fish bodies
        for (let r = 0; r < all_fish.length; r++) {
          const f = all_fish[r];
          const horizSpeed = 0.001;
          f.offset[0] += horizSpeed * (f.direction === -1 ? -1 : 1);
          if (r === 0) {
            if (keyState.w) f.offset[1] += 0.01;
            if (keyState.s) f.offset[1] -= 0.01;
          } else {
            f.offset[1] += 0.005 * Math.random();
            f.offset[1] -= 0.005 * Math.random();
          }
          if (f.direction === 1 && f.offset[0] >= 1) f.offset[0] = -1;
          if (f.direction === -1 && f.offset[0] <= -1) f.offset[0] = 1;
          if (f.offset[1] > 1) f.offset[1] = 1; if (f.offset[1] < -1) f.offset[1] = -1;
        }

        // start render pass
        const encoder = device.createCommandEncoder();
        const view = context.getCurrentTexture().createView();
        const pass = encoder.beginRenderPass({
          colorAttachments: [{
            view,
            clearValue: { r: 0, g: 0, b: 0, a: 0 },
            loadOp: 'clear',
            storeOp: 'store',
          }],
        });

        pass.setPipeline(pipeline);
        pass.setVertexBuffer(0, vbuf);
        pass.setIndexBuffer(ibuf, 'uint16');

        const tNow = performance.now() * 0.001;

        for (let r = 0; r < all_fish.length; r++) {
          const f = all_fish[r];
          // rotation + scale + direction
          const theta = Math.random() * 10 * Math.PI / 180;
          const c = Math.cos(theta), s = Math.sin(theta), sc = f.scale, d = f.direction;
          // column-major mat4
          const m = [
            d*sc*c, s,      0, 0,
            -s,    d*sc*c,  0, 0,
             0,      0,   d*sc, 0,
            f.offset[0], f.offset[1], f.offset[2], 1,
          ];
          // color (pulsating for small fish)
          let color;
          if (r === 0) {
            color = [1, 0, 0, 0.7];
          } else {
            const base = f.color;
            const a = 0.6 + 0.4 * Math.sin(tNow * 2.0);
            const p0 = r * 0.73, p1 = r * 1.11 + 1.23, p2 = r * 0.89 + 2.34;
            const rr = Math.min(Math.max(base[0] * (0.7 + 0.3 * Math.sin(tNow + p0)), 0), 1);
            const gg = Math.min(Math.max(base[1] * (0.7 + 0.3 * Math.sin(tNow + p1)), 0), 1);
            const bb = Math.min(Math.max(base[2] * (0.7 + 0.3 * Math.sin(tNow + p2)), 0), 1);
            color = [rr, gg, bb, a];
          }

          // pack body uniforms (mat4 then vec4) and upload to BODY buffer
          uni.set(m, 0);
          uni.set(color, 16);
          device.queue.writeBuffer(f.ubufBody, 0, uni.buffer, 0, uni.byteLength);

          pass.setBindGroup(0, f.bindBody);
          pass.drawIndexed(15);
          // save transform for eye pass
          f._m = m;
        }

        // Second pass: draw all eyes after bodies so they stay visible
        for (let r = 0; r < all_fish.length; r++) {
          const f = all_fish[r];
          const ex = 0.2;
          // Keep the eye on the "top" side regardless of direction and rotation.
          // Use the sign of the y-scale term (m[5]) of the body transform to detect vertical flip.
          const syTerm = f._m ? f._m[5] : 1; // m[5] = d*scale*cos(theta)
          const ey = 0.2 * (syTerm < 0 ? -1 : 1);
          // Match WebGL eye size: gl_PointSize = 20.0 * scale (pixels)
          const px = 20 * f.scale;
          const hx_ndc = px / canvas.width;
          const hy_ndc = px / canvas.height;
          const sc = f.scale || 1;
          const hx = hx_ndc / sc;
          const hy = hy_ndc / sc;
          const eyeVerts = new Float32Array([
            ex - hx, ey - hy, 0,
            ex + hx, ey - hy, 0,
            ex + hx, ey + hy, 0,
            ex - hx, ey - hy, 0,
            ex + hx, ey + hy, 0,
            ex - hx, ey + hy, 0,
          ]);
          device.queue.writeBuffer(eyeBuffer, 0, eyeVerts.buffer, 0, eyeVerts.byteLength);
          // use saved transform and semi-transparent black color
          uni.set(f._m, 0);
          uni.set([0,0,0,0.5], 16);
          device.queue.writeBuffer(f.ubufEye, 0, uni.buffer, 0, uni.byteLength);
          pass.setBindGroup(0, f.bindEye);
          pass.setVertexBuffer(0, eyeBuffer);
          pass.draw(6);
        }

        pass.end();
        device.queue.submit([encoder.finish()]);
        requestAnimationFrame(draw);
      }

      draw();
    </script>
  </body>
</html>
